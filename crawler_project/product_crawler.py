#!/usr/bin/env python3.11
# -*- coding: utf-8 -*-
"""
HPLCäº§å“ä¿¡æ¯çˆ¬è™« - æ ¸å¿ƒæ¨¡å—
ç”¨äºä»å“ç‰Œå®˜ç½‘çˆ¬å–äº§å“çš„æ–‡å­—ä¿¡æ¯(åç§°ã€æè¿°ã€æŠ€æœ¯è§„æ ¼)
"""

import pandas as pd
import json
import re
import time
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/home/ubuntu/crawler_project/logs/crawler.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class ProductCrawler:
    """äº§å“ä¿¡æ¯çˆ¬è™«åŸºç±»"""
    
    def __init__(self, brand: str):
        """
        åˆå§‹åŒ–çˆ¬è™«
        
        Args:
            brand: å“ç‰Œåç§°
        """
        self.brand = brand
        self.base_url = self._get_base_url()
        self.results = []
        self.stats = {
            'total': 0,
            'success': 0,
            'partial': 0,
            'failed': 0,
            'not_found': 0
        }
    
    def _get_base_url(self) -> str:
        """è·å–å“ç‰Œå®˜ç½‘URL"""
        url_mapping = {
            'Agilent': 'https://www.agilent.com',
            'Thermo Fisher Scientific': 'https://www.thermofisher.com',
            'Waters': 'https://www.waters.com',
            'Daicel': 'https://www.daicel.com',
            'Phenomenex': 'https://www.phenomenex.com',
            'Restek': 'https://www.restek.com',
            'Merck': 'https://www.sigmaaldrich.com',
            'Shimadzu': 'https://www.shimadzu.com',
            'ACE': 'https://www.ace-hplc.com',
            'Develosil': 'https://www.nomura-chem.co.jp',
            'Avantor': 'https://www.avantorsciences.com'
        }
        return url_mapping.get(self.brand, '')
    
    def extract_product_info(self, product_id: str, part_number: str, 
                            current_name: str) -> Dict:
        """
        æå–å•ä¸ªäº§å“çš„ä¿¡æ¯(éœ€è¦åœ¨å­ç±»ä¸­å®ç°)
        
        Args:
            product_id: äº§å“ID
            part_number: é›¶ä»¶å·
            current_name: å½“å‰äº§å“åç§°
        
        Returns:
            åŒ…å«äº§å“ä¿¡æ¯çš„å­—å…¸
        """
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç°æ­¤æ–¹æ³•")
    
    def clean_text(self, text: str) -> str:
        """
        æ¸…ç†æ–‡æœ¬å†…å®¹
        
        Args:
            text: åŸå§‹æ–‡æœ¬
        
        Returns:
            æ¸…ç†åçš„æ–‡æœ¬
        """
        if not text:
            return ""
        
        # ç§»é™¤HTMLæ ‡ç­¾
        text = re.sub(r'<[^>]+>', '', text)
        
        # ç§»é™¤å¤šä½™ç©ºç™½
        text = re.sub(r'\s+', ' ', text)
        
        # ç§»é™¤é¦–å°¾ç©ºç™½
        text = text.strip()
        
        return text
    
    def parse_specifications(self, spec_data: Dict) -> str:
        """
        å°†è§„æ ¼æ•°æ®è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
        
        Args:
            spec_data: è§„æ ¼æ•°æ®å­—å…¸
        
        Returns:
            JSONæ ¼å¼çš„è§„æ ¼å­—ç¬¦ä¸²
        """
        if not spec_data:
            return "{}"
        
        # ç¡®ä¿æ‰€æœ‰å€¼éƒ½æ˜¯å­—ç¬¦ä¸²
        cleaned_specs = {}
        for key, value in spec_data.items():
            if value is not None and value != "":
                cleaned_specs[key] = str(value).strip()
        
        return json.dumps(cleaned_specs, ensure_ascii=False)
    
    def validate_result(self, result: Dict) -> Tuple[bool, str]:
        """
        éªŒè¯çˆ¬å–ç»“æœçš„è´¨é‡
        
        Args:
            result: çˆ¬å–ç»“æœ
        
        Returns:
            (æ˜¯å¦æœ‰æ•ˆ, çŠ¶æ€æè¿°)
        """
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        if not result.get('name'):
            return False, 'missing_name'
        
        # æ£€æŸ¥äº§å“åç§°é•¿åº¦
        if len(result.get('name', '')) < 10:
            return False, 'name_too_short'
        
        # æ£€æŸ¥æè¿°
        description = result.get('description', '')
        if description == 'NOT_FOUND':
            return False, 'not_found'
        
        if not description or len(description) < 50:
            return True, 'partial'  # éƒ¨åˆ†æˆåŠŸ
        
        # æ£€æŸ¥è§„æ ¼
        try:
            specs = json.loads(result.get('specifications', '{}'))
            if len(specs) < 3:
                return True, 'partial'  # éƒ¨åˆ†æˆåŠŸ
        except:
            return True, 'partial'
        
        return True, 'success'
    
    def crawl_products(self, products: pd.DataFrame) -> List[Dict]:
        """
        æ‰¹é‡çˆ¬å–äº§å“ä¿¡æ¯
        
        Args:
            products: äº§å“DataFrame
        
        Returns:
            çˆ¬å–ç»“æœåˆ—è¡¨
        """
        self.stats['total'] = len(products)
        logger.info(f"å¼€å§‹çˆ¬å– {self.brand} çš„ {len(products)} ä¸ªäº§å“")
        
        for idx, row in products.iterrows():
            try:
                product_id = row['productId']
                part_number = row['partNumber']
                current_name = row['name']
                
                logger.info(f"[{idx+1}/{len(products)}] æ­£åœ¨çˆ¬å–: {part_number}")
                
                # æå–äº§å“ä¿¡æ¯
                result = self.extract_product_info(product_id, part_number, current_name)
                
                # éªŒè¯ç»“æœ
                is_valid, status = self.validate_result(result)
                
                if status == 'success':
                    self.stats['success'] += 1
                elif status == 'partial':
                    self.stats['partial'] += 1
                elif status == 'not_found':
                    self.stats['not_found'] += 1
                else:
                    self.stats['failed'] += 1
                
                self.results.append(result)
                
                # æ§åˆ¶è¯·æ±‚é¢‘ç‡(1-2ç§’)
                time.sleep(1.5)
                
            except Exception as e:
                logger.error(f"çˆ¬å–äº§å“ {part_number} æ—¶å‡ºé”™: {str(e)}")
                self.stats['failed'] += 1
                
                # æ·»åŠ å¤±è´¥è®°å½•
                self.results.append({
                    'productId': product_id,
                    'partNumber': part_number,
                    'brand': self.brand,
                    'name': current_name,
                    'description': 'ERROR',
                    'specifications': '{}',
                    'detailedDescription': ''
                })
        
        logger.info(f"çˆ¬å–å®Œæˆ! æˆåŠŸ: {self.stats['success']}, "
                   f"éƒ¨åˆ†: {self.stats['partial']}, "
                   f"å¤±è´¥: {self.stats['failed']}, "
                   f"æœªæ‰¾åˆ°: {self.stats['not_found']}")
        
        return self.results
    
    def save_results(self, output_file: str):
        """
        ä¿å­˜çˆ¬å–ç»“æœåˆ°CSV
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        if not self.results:
            logger.warning("æ²¡æœ‰ç»“æœå¯ä¿å­˜")
            return
        
        df = pd.DataFrame(self.results)
        df.to_csv(output_file, index=False, encoding='utf-8-sig')
        logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    def generate_report(self, output_file: str):
        """
        ç”Ÿæˆçˆ¬å–æŠ¥å‘Š
        
        Args:
            output_file: æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        success_rate = (self.stats['success'] / self.stats['total'] * 100) if self.stats['total'] > 0 else 0
        
        report = f"""# {self.brand} æ–‡å­—ä¿¡æ¯è¡¥å……æŠ¥å‘Š

**çˆ¬å–æ—¥æœŸ**: {datetime.now().strftime('%Y-%m-%d')}
**çˆ¬å–äººå‘˜**: Manus AI Agent

## ğŸ“Š çˆ¬å–ç»Ÿè®¡

- ç›®æ ‡äº§å“æ•°: {self.stats['total']}
- æˆåŠŸçˆ¬å–: {self.stats['success']}
- éƒ¨åˆ†æˆåŠŸ: {self.stats['partial']} (ç¼ºå°‘æŸäº›å­—æ®µ)
- å¤±è´¥/æœªæ‰¾åˆ°: {self.stats['failed'] + self.stats['not_found']}
- æ€»ä½“æˆåŠŸç‡: {success_rate:.1f}%

## ğŸ“‹ å­—æ®µå®Œæ•´æ€§

| å­—æ®µ | å®Œæ•´æ•°é‡ | å®Œæ•´ç‡ |
|------|---------|--------|
| name | {self._count_field('name')} | {self._calc_rate('name'):.1f}% |
| description | {self._count_field('description')} | {self._calc_rate('description'):.1f}% |
| specifications | {self._count_field('specifications')} | {self._calc_rate('specifications'):.1f}% |

## âš ï¸ é—®é¢˜äº§å“æ¸…å•

"""
        
        # æ·»åŠ é—®é¢˜äº§å“
        problem_products = []
        for result in self.results:
            if result.get('description') in ['NOT_FOUND', 'ERROR', '']:
                problem_products.append(result)
        
        if problem_products:
            report += "| productId | partNumber | é—®é¢˜æè¿° |\n"
            report += "|-----------|------------|----------|\n"
            for p in problem_products[:20]:  # åªåˆ—å‡ºå‰20ä¸ª
                desc = p.get('description', '')
                issue = 'äº§å“æœªæ‰¾åˆ°' if desc == 'NOT_FOUND' else 'çˆ¬å–å¤±è´¥' if desc == 'ERROR' else 'æè¿°ç¼ºå¤±'
                report += f"| {p['productId']} | {p['partNumber']} | {issue} |\n"
            
            if len(problem_products) > 20:
                report += f"\n... è¿˜æœ‰ {len(problem_products) - 20} ä¸ªé—®é¢˜äº§å“\n"
        else:
            report += "æ— é—®é¢˜äº§å“\n"
        
        report += f"""

## ğŸ“ ç‰¹æ®Šæƒ…å†µè¯´æ˜

- éƒ¨åˆ†äº§å“çš„æŠ€æœ¯è§„æ ¼å¯èƒ½ä¸å®Œæ•´
- éƒ¨åˆ†äº§å“åªæœ‰è‹±æ–‡æè¿°
- éµå®ˆäº†å®˜ç½‘çš„robots.txtå’Œè®¿é—®é¢‘ç‡é™åˆ¶

## ğŸ’¡ åç»­å»ºè®®

- å»ºè®®å¯¹é—®é¢˜äº§å“è¿›è¡Œäººå·¥å®¡æ ¸
- å»ºè®®ç»Ÿä¸€è§„æ ¼å­—æ®µçš„å‘½å
- å»ºè®®è¡¥å……ç¼ºå¤±çš„äº§å“æè¿°
"""
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info(f"æŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")
    
    def _count_field(self, field: str) -> int:
        """ç»Ÿè®¡å­—æ®µå®Œæ•´æ•°é‡"""
        count = 0
        for result in self.results:
            value = result.get(field, '')
            if value and value not in ['NOT_FOUND', 'ERROR', 'N/A', '{}']:
                if field == 'description' and len(value) >= 50:
                    count += 1
                elif field == 'specifications':
                    try:
                        specs = json.loads(value)
                        if len(specs) >= 3:
                            count += 1
                    except:
                        pass
                elif field == 'name' and len(value) >= 10:
                    count += 1
        return count
    
    def _calc_rate(self, field: str) -> float:
        """è®¡ç®—å­—æ®µå®Œæ•´ç‡"""
        if self.stats['total'] == 0:
            return 0.0
        return (self._count_field(field) / self.stats['total']) * 100


def load_products(csv_file: str, brand: str = None) -> pd.DataFrame:
    """
    åŠ è½½äº§å“æ¸…å•
    
    Args:
        csv_file: CSVæ–‡ä»¶è·¯å¾„
        brand: å“ç‰Œåç§°(å¯é€‰,ç”¨äºç­›é€‰)
    
    Returns:
        äº§å“DataFrame
    """
    df = pd.read_csv(csv_file)
    
    # ç»Ÿä¸€å“ç‰Œåç§°
    df['brand'] = df['brand'].replace('Thermo Fisher', 'Thermo Fisher Scientific')
    
    if brand:
        df = df[df['brand'] == brand].copy()
    
    return df


if __name__ == '__main__':
    # æµ‹è¯•ä»£ç 
    print("äº§å“çˆ¬è™«æ ¸å¿ƒæ¨¡å—å·²åŠ è½½")
    print("è¯·ä½¿ç”¨å…·ä½“çš„å“ç‰Œçˆ¬è™«ç±»è¿›è¡Œçˆ¬å–")
